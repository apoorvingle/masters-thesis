\chapter{Background Work}
% TODO should change title

\section{Type Inference Algorithm}
Algorithm W [\cite{damas_principal_1982}] and its varient algorithm M [\cite{lee_proofs_1998}]
are the basis of almost all modern statically typed programming languages. Type inference
is decidable in the sense, type checking algorithm always completes with a success or failure.
The algorithms also gurantee a most general typing scheme for an expression in
the simply typed lambda calculus extended with a polymorphic let construct having a term language
\begin{framed}
\begin{flalign*}
  \text{Expressions}\ \ \ M, N ::= x: \sigma \mid \lambda x: \tau. M \mid M N \mid \texttt{let}\ x\ \texttt{=}\ M\ \texttt{in}\ N \nonumber
\end{flalign*}
\end{framed}
and a type language specified by
\begin{framed}
\begin{flalign*}
  \text{Types}\ \ \  \tau    &::= \alpha \mid \iota \mid \tau \rightarrow \tau \nonumber \\
  \text{Typing Scheme}\ \ \  &::= \tau \mid \forall \alpha. \tau \nonumber
\end{flalign*}
\end{framed}
where $\alpha$ is a type variable, $\iota$ are primitive types in the language, $\rightarrow$
is a type constructor and $\sigma$ is a typing scheme.

Robinson's unification algorithm [\cite{robinson_machine-oriented_1965}] plays a key role
in ensuring that types are well formed. Its purely syntactic approach in creating
substitutions to unify types keeps the complete process elegent.
The algorithm works in an interesting way where the types of all well-typed terms can be
inferred automatically and if types are specified, the same algorithm can be used
to match the expression term.

\begin{figure}[h]
  \begin{framed}
    % var
    \begin{minipage}{.5\textwidth}
      \begin{prooftree}
        \AxiomC{$x: \sigma \in \Gamma$} \RightLabel{$[VAR]$}
        \UnaryInfC{$\Gamma \vdash x : \sigma $}
      \end{prooftree}
    \end{minipage}
    % let
    \begin{minipage}{.5\textwidth}
      \begin{prooftree}
        \AxiomC{$\Gamma \vdash M : \sigma \ \ \ \ \
          \Gamma_{x}, x: \sigma \vdash N: \tau$} \RightLabel{$[LET]$}
        \UnaryInfC{$\Gamma \vdash (\texttt{let}\ x\ \texttt{=}\ M\ \texttt{in}\ N) : \tau$}
      \end{prooftree}
    \end{minipage}

    % -> I
    \begin{minipage}{0.5\textwidth}
      \begin{prooftree}
        \AxiomC{$\Gamma_{x}, x: \tau \vdash M : \tau'$} \RightLabel{$[\rightarrow I]$}
        \UnaryInfC{$\Gamma \vdash \lambda x. M : \tau \rightarrow \tau'$}
      \end{prooftree}
    \end{minipage}
    % -> E
    \begin{minipage}{0.5\textwidth}
      \begin{prooftree}
        \AxiomC{$\Gamma \vdash M : \tau \rightarrow \tau' \ \ \ \ \
          \Gamma \vdash N : \tau$} \RightLabel{$[\rightarrow E]$}
        \UnaryInfC{$\Gamma \vdash M N : \tau'$}
      \end{prooftree}
    \end{minipage}
  \end{framed}
\caption{Logic rules for Simply Typed Lambda Calculus}
\label{fig:stlc-logic}
\end{figure}
The logical rules for type inference are shown in \ref{fig:stlc-logic}. $\Gamma$ is the
context or assumptions in which the expression is typed. The $[VAR]$ rule is tautology or a simple
lookup of the term variable $x$ in the context $\Gamma$. The $[LET]$ allows creating local
definitions within an expression term. $[\rightarrow I]$ and $[\rightarrow E]$ are rules
for typing lambda terms and application respectively.


% This simple type sytem is powerful in its
% expressivity and can encode a large variety of computations. The type checking algorithm
% asserts that undefined programs can be be detected statically i.e. without actually
% running the program or as famously known as ``well typed programs do not go wrong''.
% This is extremely useful for programmers who are building
% complex real world softwares. Bad programs can be eleminated instantaneously while
% being written using a mechanize technique so that the programmer can concentrate on designing the logic
% rather than fighting undefinedness of the programs. This creates an excellent feedback loop
% to the programmer while building large software systems. % TODO too generic should it be in introduction?
% TODO Give examples?


\section{Qualified Types}
Jones [\cite{jones_theory_1994}] proposed incorporating predicates in the type language.
Predicates are used to build constraints on the domain of the type of a term in the language expression.
It introduces additional layer between polymorphic and monomorphic typing of programs.
A modification of Milner-Damas algorithm to encorporate predicates ensures that type inference
is sound and complete. The types that satisfy all the predicates are called qualified types for the term.
Qualified types are powerful enough to expresses type classes with functional dependencies,
record types and subtyping [\cite{mark_type_2000}]. The type language is modified to contain
qualified types. $\Pi$ and $T$ range over finite set of predicates
\begin{framed}
\begin{flalign*}
  \text{Types}\ \ \ \tau              &::= \alpha \mid \iota \mid \tau \rightarrow \tau \nonumber \\
  \text{Qualified Types}\ \ \ \rho    &::= \Pi \Rightarrow \tau \nonumber \\
  \text{Type Scheme}\ \ \ \sigma      &::= \tau \mid \forall T. \rho \nonumber
\end{flalign*}
\end{framed}

\section{Linear Logic}
% TODO: points to cover
% what is linearity
% restricting weakening and contraction

Girard \cite{girard_linear_1987} invented linear logic,
where contraction and weakening of logical rules was restricted.
The idea was that propositions cannot be freely duplicated or
discarded like in classical logic. This instigates a view of
propositions to behave like resources. In real world software applications,
resources may not be freely copied or dropped from a program context.
Program entities like database connections, file handles or even
in memory shared state are pet peeves for programmers writing
industry grade software. Linear logic hopes to be a remedy for
these problems.

It was directly translated to handling of resources by the means of types. There has been
active research in linear logic and its application s
in programming languages. The hope being it can elevate
certain problems such as resource leaks in programs that
are extremly tough to detect and remediate from a full
fledged industry grade software. Linear logic is believed
to posseses the power to

\section{Bunched Implications and $\alpha$ Lambda Calculus}
$\alpha$ Lambda calculus introduces 2 kinds of arrows due the theory
developed by O'Hearn and Pym [\cite{ohearn_logic_1999}]
$\sepimp$     : Arguments of function do not share resources with their arguments
$\rightarrow$ : Arguments of functions may share resources with their arguments
and 2 new varieties of bunches $\Gamma; \Delta$ and $\Gamma, \Delta$ where
the former admits to weakening and contraction but the later does not.

This is where $\alpha$ lambda calculus is introduced. we consider resources
magic wand?


\section{Linear logic with qualified types: Quill}
combining linear logic with qualified types in Quill \cite{morris_best_2016}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
